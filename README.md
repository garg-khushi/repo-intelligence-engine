# Repo Intelligence Engine

An LLM-powered system for understanding, exploring, and querying software repositories using retrieval-augmented generation (RAG).

This project enables users to ask natural language questions about a codebase and receive context-grounded answers by combining document ingestion, embeddings, vector search, and conversational reasoning.

---

## ğŸš€ What This Project Does

- Clones a public GitHub repository
- Parses source files and documentation
- Splits code into semantic chunks
- Generates vector embeddings
- Stores embeddings in a vector database
- Enables conversational Q&A grounded in repository context

This allows questions such as:
- *"What does this project do?"*
- *"How is authentication handled?"*
- *"Where is the main training loop defined?"*
- *"Explain the data flow in this codebase."*

---

## ğŸ§  System Architecture

```
GitHub Repo
â†‘
â†‘
File Loader & Parser
â†‘
Text Chunking
â†‘
Embedding Model
â†‘
Vector Store (Chroma)
â†‘
Retriever
â†‘
LLM (Conversational QA)
â†‘
Streamlit UI
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-----|----------|
| Language | Python |
| UI | Streamlit |
| LLM | OpenAI GPT models |
| Framework | LangChain |
| Embeddings | OpenAI Embeddings |
| Vector Store | Chroma |
| Version Control | Git |

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ app_updated.py              # Main Streamlit application
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Projreport_OpenAI.docx    # Project report and documentation
â””â”€â”€ data/                       # Vector store persistence (generated)
```

---

## ğŸ”¬ï¸ What's Implemented

- âœ… GitHub repository cloning
- âœ… File loading and preprocessing
- âœ… Chunk-based embedding generation
- âœ… Vector search using Chroma
- âœ… Conversational retrieval QA
- âœ… Interactive Streamlit interface

---

## âš ï¸ Scope & Limitations

- Designed for **demonstration and experimentation**
- Not optimized for very large repositories
- Embedding persistence is local
- Security hardening and sandboxing are out of scope

This project intentionally prioritizes **clarity and correctness** over production scaling.

---

## ğŸ˜§ Planned Enhancements

- Per-repository isolated vector stores
- Language-aware file parsing
- Support for multiple embedding models
- Repository summarization and dependency graphs
- Deployment-ready API layer (FastAPI)

---

## ğŸ‘¨â€ğŸ’» How to Run Locally

```bash
git clone https://github.com/garg-khushi/repo-intelligence-engine.git
cd repo-intelligence-engine
pip install -r requirements.txt
streamlit run app_updated.py
```

Create a `.env` file with:
```
OPENAI_API_KEY=your_api_key_here
```

---

## ğŸ¯ Why This Project Matters

This project demonstrates:
- Practical use of LLMs beyond chat
- Retrieval-augmented generation pipelines
- Vector databases and semantic search
- Developer tooling and code intelligence systems

It reflects real-world patterns used in modern AI-powered developer platforms.

---

## ğŸ“ƒ License

MIT
